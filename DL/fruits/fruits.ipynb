{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Func\n",
    "import torchvision as tv\n",
    "import albumentations as A\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = tv.transforms.Compose([\n",
    "    tv.transforms.Resize((100,100)),\n",
    "    tv.transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = 'C:/Users/kryzh/dataset/training_set/training_set'\n",
    "path_train = 'C:/Users/kryzh/dataset/Fruits/Training'\n",
    "dataset_train = tv.datasets.ImageFolder(root=path_train, transform=transforms)\n",
    "path_val = 'C:/Users/kryzh/dataset/Fruits/Training'\n",
    "dataset_val = tv.datasets.ImageFolder(root=path_val, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(dataset[2][0].numpy().transpose((1,2,0)))\n",
    "# dataset[2][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train=torch.utils.data.DataLoader(dataset_train, batch_size=16,shuffle=True, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNA(nn.Module):\n",
    "    def __init__(self, in_nc=32,out_nc=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv=nn.Conv2d(in_nc,out_nc,kernel_size=3,padding=1) #128 128\n",
    "        self.norm=nn.BatchNorm2d(out_nc)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out=self.conv(x)\n",
    "        out=self.norm(out)\n",
    "        out=self.act(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "net = CNA()\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvNet(nn.Module):\n",
    "    def __init__(self, base_nc=32):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.flatten =nn.Flatten()\n",
    "        # self.Linear1=nn.Linear(784,100)\n",
    "        # self.act=nn.Sigmoid()\n",
    "        # self.LInear2=nn.Linear(100,10)\n",
    "        maxpool=nn.MaxPool2d(2,2)\n",
    "        avgpool=nn.AdaptiveAvgPool2d((1,1))\n",
    "        act = nn.ReLU()\n",
    "        Linear1 = nn.Linear(4*base_nc,10)\n",
    "\n",
    "        flatten = nn.Flatten()\n",
    "\n",
    "        cna1_1=CNA(3,base_nc)\n",
    "        cna1_2=CNA(base_nc,base_nc)\n",
    "\n",
    "        cna2_1=CNA(base_nc,2*base_nc)\n",
    "        cna2_2=CNA(2*base_nc, 2*base_nc)\n",
    "\n",
    "        cna3_1=CNA(2*base_nc,4*base_nc)\n",
    "        cna3_2=CNA(4*base_nc,4*base_nc)\n",
    "        \n",
    "        cna4_1=CNA(4*base_nc,4*base_nc)\n",
    "        cna4_2=CNA(4*base_nc,4*base_nc)\n",
    "        \n",
    "        cna5_1=CNA(4*base_nc,4*base_nc)\n",
    "        cna5_2=CNA(4*base_nc,4*base_nc)\n",
    "\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            cna1_1,cna1_2,maxpool,\n",
    "            cna2_1,cna2_2,maxpool,\n",
    "            cna3_1,cna3_2,maxpool,\n",
    "            cna4_1,cna4_2,maxpool,\n",
    "            cna5_1,cna5_2,avgpool,\n",
    "            flatten,Linear1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.model(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "vggNet=tv.models.vgg.vgg19(weights=tv.models.VGG19_Weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=nn.Sequential(\n",
    "    nn.Linear(25088,600),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(600,600),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(600,131)\n",
    ")\n",
    "vggNet.classifier=classifier\n",
    "for param in vggNet.features.parameters():\n",
    "    param.requires_grad=False\n",
    "#net = SimpleConvNet()\n",
    "net=vggNet\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=600, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=600, out_features=600, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=600, out_features=131, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(net):\n",
    "    return sum(p.numel() for p in net.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15492731\n"
     ]
    }
   ],
   "source": [
    "print(count_parameters(net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_fn=nn.BCEWithLogitsLoss().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "#loss_fn=nn.MSELoss()\n",
    "optimizer=torch.optim.Adam(net.classifier.parameters(),lr=1e-4, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(pred, label):\n",
    "    answer = pred.detach().numpy().argmax(1) == label.numpy().argmax(1) \n",
    "    return answer.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 4231/4231 [01:41<00:00, 41.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 0.21880428840275434 accruracy= 0.9535275348617348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 4231/4231 [01:38<00:00, 42.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 0.020072016530624074 accruracy= 0.9954502481682818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 4231/4231 [01:37<00:00, 43.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 0.0162684595355872 accruracy= 0.9961149846372016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs=3\n",
    "for epoch in range(epochs):\n",
    "    loss_val=0\n",
    "    acc_val=0\n",
    "\n",
    "    for sample in tqdm(dataloader_train):\n",
    "        img,label = sample\n",
    "\n",
    "        label = label.to(device)\n",
    "        label = Func.one_hot(label, num_classes=131).float()\n",
    "        # label=Func.one_hot(label,num_classes=10)\n",
    "        #label = label.float()\n",
    "        #label = label.unsqueeze(1)\n",
    "        img = img.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = net (img)\n",
    "\n",
    "        loss = loss_fn(pred, label)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_val+=loss.item()\n",
    "        acc_val += get_accuracy(pred.cpu(), label.cpu())\n",
    "    loss_val /= len(dataloader_train)\n",
    "    acc_val /= len(dataloader_train)\n",
    "    print(\"loss=\",loss_val ,\"accruracy=\",acc_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'C:/Users/kryzh/dataset/test_set/test_set'\n",
    "# testset = tv.datasets.ImageFolder(root=path, transform=transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader=torch.utils.data.DataLoader(dataset_val, batch_size=1,shuffle=True, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9926726939667908\n"
     ]
    }
   ],
   "source": [
    "acc_val=0\n",
    "for sample in testloader:\n",
    "    img,label = sample\n",
    "    #plt.imshow(img.numpy().transpose((1,2,0)))\n",
    "    \n",
    "    label = label.to(device)\n",
    "    label = Func.one_hot(label, num_classes=131).float()\n",
    "    img = img.to(device)\n",
    "    #label = label.unsqueeze(1)\n",
    "    pred = net(img)\n",
    "    acc_val += get_accuracy(pred.cpu(), label.cpu())\n",
    "    #print(acc_val)\n",
    "    #print( pred,label)\n",
    "print(acc_val/len(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader=torch.utils.data.DataLoader(dataset_train, batch_size=1,shuffle=True, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9926726939667908\n"
     ]
    }
   ],
   "source": [
    "acc_val=0\n",
    "for sample in dataloader:\n",
    "    img,label = sample\n",
    "    #plt.imshow(img.numpy().transpose((1,2,0)))\n",
    "    \n",
    "    label = label.to(device)\n",
    "    label = Func.one_hot(label, num_classes=131).float()\n",
    "    img = img.to(device)\n",
    "    #label = label.unsqueeze(1)\n",
    "    pred = net(img)\n",
    "    acc_val += get_accuracy(pred.cpu(), label.cpu())\n",
    "    #print(acc_val)\n",
    "    #print( pred,label)\n",
    "print(acc_val/len(dataloader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
